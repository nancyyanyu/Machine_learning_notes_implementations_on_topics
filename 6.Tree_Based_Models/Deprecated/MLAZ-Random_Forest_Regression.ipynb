{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Ideas\n",
    "Random forests is a substantial modification of bagging that builds a large collection of de-correlated trees, and then averages them.\n",
    "\n",
    "## Definition of Random Forests\n",
    "**Bagging**: The essential idea in bagging is to average many noisy but approximately unbiased models, and hence reduce the variance. *Trees* are ideal candidates for bagging, since they can capture complex interaction structures in the data, and if grown sufficiently deep, have relatively low bias.\n",
    "\n",
    ">A complicated decision tree (e.g. deep) has low bias and high variance. The bias-variance tradeoff does depend on the depth of the tree.\n",
    "\n",
    "\n",
    "A visual representation of the terms bias and variance             |   A curve of squared bias vs variance showing the inverse correlation \n",
    ":-------------------------:|:-------------------------:\n",
    "<img src=\"./images/bias-var.png\" width=250> | <img src=\"./images/bias-var2.png\" width=300>\n",
    "\n",
    "An average of B i.i.d. random variables, each with variance $\\sigma^2$, has variance $\\frac{1}{B^2}$. If the variables are simply i.d. (identically distributed, but not necessarily independent) with positive pairwise correlation $\\rho$, the variance of the average is:\n",
    "\n",
    "\\begin{align}\n",
    "\\rho\\sigma^2+\\frac{1-\\rho}{B}\\sigma^2\n",
    "\\end{align}\n",
    "\n",
    "As B increases, the second term disappears, but the first remains, and hence the size of the correlation of pairs of bagged trees limits the benefits of averaging. \n",
    "\n",
    "### Intuition of random forests\n",
    "The idea in random forests is to improve the **variance reduction of bagging** by **reducing the correlation between the trees**, without increasing the variance too much. This is achieved in the tree-growing process through *random selection of the input variables*.\n",
    "\n",
    "### Algorithms of random forests\n",
    "Specifically, when growing a tree on a bootstrapped dataset:\n",
    ">Before each split, select m $\\leq$ p of the input variables at random\n",
    "as candidates for splitting.\n",
    "\n",
    "Typically values for m are $\\sqrt{p}$ or even as low as 1.\n",
    "\n",
    "After B such trees $\\{T(x;\\theta_b)\\}_1^B$are grown, the random forest (regression)\n",
    "predictor is:\n",
    "\n",
    "\\begin{align}\n",
    "\\hat{f}_{rf}^B(x)=\\frac{1}{B}\\sum_{b=1}^BT(x;\\theta_b)\n",
    "\\end{align}\n",
    "\n",
    "$\\theta_b$ characterizes the bth random forest tree in terms of split variables, cutpoints at each node, and terminal-node values.\n",
    "\n",
    "Intuitively, reducing m will reduce the correlation between any pair of trees in the ensemble, and hence reduce the variance of the average.\n",
    "\n",
    "<img src=\"./images/rf1.png\" width=400> \n",
    "\n",
    "\n",
    "In Random Forest, only a random subset of the features is taken into consideration by the algorithm for splitting a node. You can even make trees more random, by additionally using random thresholds for each feature rather than searching for the best possible thresholds (like a normal decision tree does)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df=pd.read_csv('./data/Position_Salaries.csv')\n",
    "X=df.iloc[:,1:-1].values\n",
    "y=df.iloc[:,-1:].values\n",
    "\n",
    "# Feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "stan_x=StandardScaler()\n",
    "stan_y=StandardScaler()\n",
    "X=stan_x.fit_transform(X)\n",
    "y=stan_y.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=300, n_jobs=None,\n",
       "           oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting random forests\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regressor=RandomForestRegressor(n_estimators=300,random_state=0)\n",
    "regressor.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a245c67f0>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot\n",
    "X_grid=np.arange(min(X),max(X),0.01)\n",
    "X_grid=X_grid.reshape((X_grid.shape[0],1))\n",
    "plt.scatter(X,y,color='blue')\n",
    "plt.plot(X_grid,regressor.predict(X_grid),color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.96177845])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.predict([[6.5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions\n",
    "## What is the advantage and drawback of Random Forests compared to Decision Trees? \n",
    "**Advantage:** Random Forests can give you a better predictive power than Decision Trees.\n",
    "**Drawback: **Decision Tree will give you more interpretability than Random Forests, because you can plot the\n",
    "graph of a Decision Tree to see the diﬀerent splits leading to the prediction, as seen in the Intuition Lecture.\n",
    "That’s something you can’t do with Random Forests.\n",
    "\n",
    "## When to use Random Forest and when to use the other models?\n",
    "The best answer to that question is: try them all!\n",
    "\n",
    "However , if you want some shortcuts, here are some rules of thumbs to help you decide which model to\n",
    "use:\n",
    "\n",
    "1. you need to ﬁgure out whether your problem is linear or non linear. You will learn how to do that in Model Selection.\n",
    " - If your problem is linear, you should go for Simple Linear Regression if you only have one feature, and Multiple Linear Regression if you have several features.\n",
    " - If your problem is non linear, you should go for Polynomial Regression, SVR, Decision Tree or Random Forest. Then which one should you choose among these four? That you will learn in Part 10 - Model Selection. \n",
    " \n",
    "2. The method consists of using a very relevant technique that evaluates your models performance,called **k-Fold Cross Validation**, and then picking the model that shows the best results. \n",
    "\n",
    "## How do I know how many trees I should use?\n",
    "1. I would recommend to choose the number of trees by experimenting. It usually takes less time than we think to ﬁgure out a best value by tweaking and tuning your model manually. That’s actually what we do in general when we build a Machine Learning model: we do it in several shots, by experimenting several values of hyperparameters like the number of trees. \n",
    "2. k-Fold Cross Validation and Grid Search, which are powerful techniques that you can use to ﬁnd the optimal value of a hyperparameter, like here the number of trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
