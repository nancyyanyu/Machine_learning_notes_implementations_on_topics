{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Subset Selection\n",
    "\n",
    "**Approach**\n",
    "\n",
    "1. fit a separate least squares regression best subset for each possible combination of the p predictors. That is, we fit all p models selection that contain exactly one predictor, all $\\left(\\begin{array}{c}p\\\\ 2\\end{array}\\right)= p(p−1)/2$ models that contain exactly two predictors, and so forth. \n",
    "\n",
    "2. We then look at all of the resulting\n",
    "models, with the goal of identifying the one that is best.\n",
    "\n",
    "<img src=\"./images/1.png\" width=600>\n",
    "\n",
    "**Note**\n",
    "\n",
    "- $RSS$ of these p + 1 models decreases monotonically, and the $R2$ increases\n",
    "monotonically, as the number of features included in the models increases.\n",
    "Therefore, if we use these statistics to select the best model, then we will\n",
    "always end up with a model involving all of the variables\n",
    "- The problem of selecting the best model from among the $2^p$ possibilities\n",
    "considered by best subset selection is not trivial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stepwise Selection\n",
    "## Forward Stepwise Selection\n",
    "\n",
    "**Approach**\n",
    "\n",
    "1. **Forward stepwise selection** begins with a model containing no predictors, and then adds predictors\n",
    "to the model, one-at-a-time, until all of the predictors are in the model.\n",
    "\n",
    "2. In particular, at each step the variable that gives the greatest additional\n",
    "improvement to the fit is added to the model.\n",
    "\n",
    "<img src=\"./images/2.png\" width=600>\n",
    "\n",
    "\n",
    "**Forward Stepwise Selection V.S. Best Subset Selection**\n",
    "\n",
    "- Forward stepwise selection’s computational advantage over best subset\n",
    "selection is clear. \n",
    "- Forward stepwise is not guaranteed to find the best possible model out of all $2^p$ models\n",
    "containing subsets of the p predictors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backward Stepwise Selection\n",
    "\n",
    "**Approach**\n",
    "\n",
    "1. **Backward Stepwise Selection** begins with the full least squares model containing all p predictors, and then iteratively removes the least useful predictor, one-at-a-time\n",
    "\n",
    "\n",
    "<img src=\"./images/3.png\" width=600>\n",
    "\n",
    "**Backward Stepwise Selection V.S. Forward Stepwise Selection**:\n",
    "\n",
    "- Like forward stepwise selection, the backward selection approach searches\n",
    "through only 1+p(p+1)/2 models, and so can be applied in settings where\n",
    "p is too large to apply best subset selection.\n",
    "- Like forward stepwise selection, backward stepwise selection is not guaranteed to yield the best\n",
    "model containing a subset of the p predictors.\n",
    "- Backward selection requires that the number of samples n is larger than\n",
    "the number of variables p (so that the full model can be fit). In contrast,\n",
    "forward stepwise can be used even when n < p, and so is the only viable\n",
    "subset method when p is very large.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hybrid Approaches\n",
    "\n",
    "**Approach**\n",
    "\n",
    "1. Variables are added to the model sequentially, in analogy to forward selection. \n",
    "2. However, after adding each new variable, the method\n",
    "may also remove any variables that no longer provide an improvement in\n",
    "the model fit. \n",
    "\n",
    "**Note**\n",
    "\n",
    "Such an approach attempts to more closely mimic best subset\n",
    "selection while retaining the computational advantages of forward and\n",
    "backward stepwise selection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choosing the Optimal Model \n",
    "\n",
    "The training error can be a poor estimate of the test error. Therefore, RSS and R2 are not suitable for selecting the best model among a collection of models with different numbers of predictors.\n",
    "\n",
    "**2 Methods**:\n",
    "\n",
    "1. *indirectly* estimate test error by making an adjustment to the\n",
    "training error to account for the bias due to overfitting.\n",
    "\n",
    "2. *directly* estimate the test error, using either a validation set\n",
    "approach or a cross-validation approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $C_p$, $AIC$, $BIC$, Adjusted $R^2$ \n",
    "\n",
    "- the training set MSE is generally an underestimate of the test MSE. (Recall that MSE = RSS/n.)\n",
    "- the training error will decrease as more variables are included in the model, but the test error may not. \n",
    "- Therefore, training set RSS and training set R2 cannot be used to select from among a set of models with different numbers of variables.\n",
    "\n",
    "### $C_p$\n",
    "\n",
    "$C_p$ estimate of test MSE:\n",
    "\n",
    "\\begin{align}\n",
    "C_p=\\frac{1}{n}(RSS+2d\\hat{\\sigma}^2)\n",
    "\\end{align}\n",
    "\n",
    "where $\\hat{\\sigma}^2$ is an estimate of the variance of the error $\\epsilon$\n",
    "\n",
    "**Note**:\n",
    "- The $C_p$ statistic adds a penalty of $2d\\hat{\\sigma}^2$ to the training RSS in order to adjust for the fact that the training error tends to underestimate the test error.\n",
    "- The penalty increases as the number of predictors in the model increases; this is intended to adjust\n",
    "for the corresponding decrease in training RSS.\n",
    "- If $\\hat{\\sigma}^2$ is an unbiased estimate of $\\sigma^2$ in, then $C_p$ is an unbiased estimate of test MSE\n",
    "- When determining which of a set of models is best, we choose the model with the lowest $C_p$ value.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AIC\n",
    "The AIC criterion is defined for a large class of models fit by maximum\n",
    "likelihood. In the case of the model $Y = β_0 + β_1X_1 + · · · + β_pX_p + \\epsilon$ with Gaussian errors, maximum\n",
    "likelihood and least squares are the same thing. \n",
    "\n",
    "In this case AIC is given by\n",
    "\n",
    "\\begin{align}\n",
    "AIC=\\frac{1}{n\\hat{\\sigma}^2}(RSS+2d\\hat{\\sigma}^2)\n",
    "\\end{align}\n",
    "\n",
    "For least\n",
    "squares models, Cp and AIC are proportional to each other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BIC\n",
    "For the least squares model with d predictors, the\n",
    "BIC is, up to irrelevant constants, given by\n",
    "\n",
    "\n",
    "\\begin{align}\n",
    "BIC=\\frac{1}{n}(RSS+\\log(n)d\\hat{\\sigma}^2)\n",
    "\\end{align}\n",
    "\n",
    "Since log(n) > 2 for any n > 7,\n",
    "the BIC statistic generally places a heavier penalty on models with many\n",
    "variables, and hence results in the selection of smaller models than Cp."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjusted $R^2$ \n",
    "\n",
    "Recall:\n",
    "\\begin{align}\n",
    "R^2=1 − RSS/TSS=1-\\frac{RSS}{\\sum(y_i-\\bar{y})^2}\n",
    "\\end{align}\n",
    "\n",
    "**TSS**: total sum of squares for the response\n",
    "\n",
    "For a least squares model with d variables,\n",
    "**the adjusted R2** statistic is calculated as\n",
    "\n",
    "\\begin{align}\n",
    "Adjusted  \\, R^2=1 − \\frac{RSS/(n-d-1)}{TSS/(n-1)}\n",
    "\\end{align}\n",
    "\n",
    "**Note**:\n",
    "\n",
    "- a large value of adjusted R2 indicates a model with a\n",
    "small test error. Maximizing the adjusted R2 is equivalent to minimizing $RSS/(n−d−1)$\n",
    "- $RSS/(n−d−1)$ may increase or decrease, due to the presence of d in the\n",
    "denominator.\n",
    "\n",
    "**Intuition**:\n",
    "- once all of the correct\n",
    "variables have been included in the model, adding additional noise variables will lead to only a very small decrease in RSS\n",
    "- Unlike the R2 statistic, the adjusted R2 statistic pays\n",
    "a price for the inclusion of unnecessary variables in the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation and Cross-Validation \n",
    "\n",
    "As an alternative to the approaches just discussed, we can compute the validation set error or the\n",
    "cross-validation error for each model under consideration, and then select\n",
    "the model for which the resulting estimated test error is smallest. \n",
    "\n",
    "**Advantage over $C_p, AIC, BIC$**: \n",
    "- Direct estimate of the test error, and makes fewer assumptions\n",
    "about the true underlying model. \n",
    "- Used in a wider range of\n",
    "model selection tasks, even in cases where it is hard to pinpoint the model\n",
    "degrees of freedom or hard to\n",
    "estimate the error variance σ2.\n",
    "\n",
    "\n",
    "**One-standard-error rule**: We first calculate the standard error of the estimated test MSE for each model size, and then select the smallest model for which the estimated test error is within one\n",
    "standard error of the lowest point on the curve.\n",
    " - **Rationale**: if a set of models appear to be more or less equally good, then we might\n",
    "as well choose the simplest model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
