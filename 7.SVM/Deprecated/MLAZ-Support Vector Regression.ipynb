{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Whats the main difference between SVR and a simple regression model?**\n",
    "In simple regression we try to minimise the error rate. While in SVR we try to fit the error within a certain threshold. \n",
    "\n",
    "Terms:\n",
    "1. **Kernel**: The function used to map a lower dimensional data into a higher dimensional data.\n",
    "2. **Hyper Plane**: In SVM this is basically the separation line between the data classes. Although in SVR we are going to define it as the line that will will help us predict the continuous value or target value\n",
    "3. **Boundary line**: In SVM there are two lines other than Hyper Plane which creates a margin . The support vectors can be on the Boundary lines or outside it. This boundary line separates the two classes. In SVR the concept is same.\n",
    "4. **Support vectors**: This are the data points which are closest to the boundary. The distance of the points is minimum or least."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Idea\n",
    "\n",
    "our goal is to find a function f(x) that has at most ε deviation from the actually obtained targets yi for all\n",
    "the training data, and at the same time is as flat as possible. In other words, we do not care about errors as long as they are less than ε, but will not accept any deviation larger than this.\n",
    "\n",
    "We begin by describing the case of linear functions f, taking the form:\n",
    "\n",
    "\\begin{align}\n",
    "f(x)=\\langle w,x \\rangle+b\n",
    "\\end{align}\n",
    "\n",
    " where <~,~>  denotes the dot product \n",
    " \n",
    "**Flatness** in the case means that one seeks a small w. One way to ensure this is to minimize the norm,i.e.$||w||^2, \\langle w,x \\rangle$\n",
    "\n",
    "\\begin{align}\n",
    "\\min \\frac{1}{2}||w||^2  \\\\\n",
    "s.t.  y_i-\\langle w,x_i \\rangle-b &\\leq \\epsilon \\\\\n",
    "y_i-\\langle w,x_i \\rangle-b &\\geq -\\epsilon\n",
    "\\end{align}\n",
    "\n",
    "<img src=\"./images/svr1.png\" width=200>\n",
    "\n",
    "The tacit assumption in restriction was that such a function f actually exists that approximates all pairs (xi, yi) with ε precision, or in other words, that the convex optimization problem is **feasible**.\n",
    "\n",
    "## Soft Margin\n",
    "\n",
    "\\begin{align}\n",
    "\\min \\frac{1}{2}||w||^2+C\\sum_{i=1}^l(\\xi_i+\\xi^*_i)  \\\\\n",
    "s.t.  y_i-\\langle w,x_i \\rangle-b &\\leq \\epsilon+\\xi_i \\\\\n",
    "\\langle w,x_i \\rangle+b-y_i &\\leq \\epsilon+\\xi_i^* \\\\\n",
    "\\xi_i,\\xi_i^* &\\geq 0\n",
    "\\end{align}\n",
    "\n",
    "<img src=\"./images/svr2.png\" width=200>\n",
    "\n",
    "The constant C > 0 determines the trade-off between the flatness of f and the amount up to which deviations larger than ε are tolerated. Only the points outside the shaded region contribute to the cost insofar, as the\n",
    "deviations are penalized in a linear fashion.\n",
    "\n",
    "<img src=\"./images/svr3.png\" width=300>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dual Problem and Quadratic Programms\n",
    "The key idea is to construct a Lagrange function from the **primal** function and the corresponding constraints,\n",
    "by introducing a dual set of variables. \n",
    "\n",
    "\\begin{align}\n",
    "L = \\frac{1}{2}||w||^2 &+C\\sum_{i=1}^l(\\xi_i+\\xi^*_i)  - \\sum_{i=1}^l(\\eta_i \\xi_i+\\eta_i^* \\xi_i^*)  \\\\\n",
    "                & -\\sum_{i=1}^l \\alpha_i(\\epsilon+\\xi_i-y_i+\\langle w,x_i \\rangle+b) \\\\\n",
    "                & -\\sum_{i=1}^l \\alpha_i^*(\\epsilon+\\xi_i^*+y_i-\\langle w,x_i \\rangle-b) \\\\\n",
    "\\end{align}\n",
    "  \n",
    "It follows from the saddle point condition that the partial derivatives of L with respect to the primal variables\n",
    "($w,b,\\xi_i,\\xi_i^*$) have to vanish for optimality.  \n",
    "\n",
    "\\begin{align}\n",
    "\\partial_b L  &= \\sum_{i=1}^l(\\alpha_i^*-\\alpha_i)=0  \\\\\n",
    "\\partial_w L  &= w- \\sum_{i=1}^l(\\alpha_i-\\alpha_i^*) x_i=0 \\\\\n",
    "\\partial_{\\xi^{(*)}} L  &= C-\\eta^{(*)}-\\alpha^{(*)}=0\n",
    "\\end{align} \n",
    "\n",
    "Substituting them into L yields the dual optimization problem.\n",
    "\\begin{align}\n",
    "\\max &-\\frac{1}{2}\\sum_{i,j=1}^l(\\alpha_i-\\alpha_i^*)(\\alpha_j-\\alpha_j^*)\\langle x_i,x_j \\rangle -\\epsilon \\sum_{i=1}^l(\\alpha_i+\\alpha_i^*)+ \\sum_{i=1}^l y_i(\\alpha_i-\\alpha_i^*) \\\\\n",
    "s.t & \\sum_{i=1}^l(\\alpha_i^*-\\alpha_i)=0 ; \\alpha_i^*,\\alpha_i \\in [0,C]\n",
    "\\end{align} \n",
    "\n",
    "<img src=\"./images/svr4.png\" width=450>\n",
    "\n",
    "## Support Vector expansion\n",
    "\n",
    "Because $w= \\sum_{i=1}^l(\\alpha_i-\\alpha_i^*) x_i$, so that:\n",
    "\n",
    "\\begin{align}\n",
    "f(x)=\\sum_{i=1}^l(\\alpha_i-\\alpha_i^*) \\langle x_i,x \\rangle+b\n",
    "\\end{align} \n",
    "\n",
    "$w$ can be completely described as a linear combination of the training patterns xi. In a sense, the complexity of a function’s representation by SVs is independent of the dimensionality of the input space X, and depends only on the number of SVs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-linear SVR\n",
    "\n",
    "\\begin{align}\n",
    "f(x)&=\\sum_{i=1}^l(\\alpha_i-\\alpha_i^*) \\langle \\phi(x_i),\\phi(x) \\rangle+b \\\\\n",
    "f(x)&=\\sum_{i=1}^l(\\alpha_i-\\alpha_i^*)  K(x_i,x) +b\n",
    "\\end{align} \n",
    "\n",
    "## Kernel functions\n",
    "\n",
    "1. polynomial\n",
    "\\begin{align}\n",
    "K(x_i,x_j) =\\langle x_i,x_j \\rangle^d=(x_i^T x_j+1)^d\n",
    "\\end{align}\n",
    "\n",
    "2. Guassian Radial Basis\n",
    "\\begin{align}\n",
    "K(x_i,x_j) =exp(-\\frac{||x_i-x_j||^2}{2\\sigma^2})\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a SVR\n",
    "1. Collect training data $\\tau=(X,Y)$\n",
    "2. Choose kernel, and regularization\n",
    "3. Form the correlation matrix K\n",
    "4. Train your machine to get contraction coefficients $\\alpha=\\{\\alpha_i\\}$\n",
    "5. Use these coefficients to create your predictor $f(X,\\alpha,x^*)=y^*$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df=pd.read_csv('./data/Position_Salaries.csv')\n",
    "X=df.iloc[:,1:-1].values\n",
    "y=df.iloc[:,-1:].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nancy/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/nancy/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/nancy/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/nancy/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# Feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "stan_x=StandardScaler()\n",
    "stan_y=StandardScaler()\n",
    "X=stan_x.fit_transform(X)\n",
    "y=stan_y.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nancy/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([170370.0204065])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting SVR to the dataset\n",
    "from sklearn.svm import SVR\n",
    "regressor=SVR(kernel='rbf')\n",
    "regressor.fit(X,y)\n",
    "\n",
    "\n",
    "#Predict a new data point\n",
    "y_pred=stan_y.inverse_transform(regressor.predict(stan_x.transform(np.array([[6.5]]))))\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f21b1cb03c8>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X,y,color='blue')\n",
    "plt.plot(X,regressor.predict(X),color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions\n",
    "\n",
    "## When should I use SVR?\n",
    "You should use SVR if a linear model like linear regression doesn’t ﬁt very well your data. This would mean\n",
    "you are dealing with a **non linear problem**, where your data is not linearly distributed. Therefore in that\n",
    "case SVR could be a much better solution.\n",
    "\n",
    "## Why do we need to ’sc_Y.inverse_transform’?\n",
    "We need the inverse_transform method to go back to the original scale. Indeed we applied feature scaling\n",
    "so we get this scale around 0 and if we make a prediction without inversing the scale we will get the\n",
    "scaled predicted salary. And of course we want the real salary, not the scaled one, so we have to use\n",
    "’sc_Y.inverse_transform’. Also what is important to understand is that ’transform’ and ’inverse_transform’\n",
    "are paired methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
