{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "Reference: Trevor Hastie, Robert Tibshirani, Jerome Friedman The elements of statistical learning Data mining, inference, and prediction\n",
    "\n",
    "\n",
    "The logistic regression model arises from the desire to model the posterior probabilities of the K classes via linear functions in x, while at the same time ensuring that they sum to one and remain in [0, 1]. The model has\n",
    "the form:\n",
    "\n",
    "\n",
    "\\begin{align}\n",
    "\\log\\frac{\\text{Pr}(G=1|X=x)}{\\text{Pr}(G=K|X=x)} &= \\beta_{10} + \\beta_1^Tx \\\\\n",
    "\\log\\frac{\\text{Pr}(G=2|X=x)}{\\text{Pr}(G=K|X=x)} &= \\beta_{20} + \\beta_2^Tx \\\\\n",
    "&\\vdots \\\\\n",
    "\\log\\frac{\\text{Pr}(G=K-1|X=x)}{\\text{Pr}(G=K|X=x)} &= \\beta_{(K-1)0} + \\beta_{K-1}^Tx \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
